# Queue System

TinyClaw uses a file-based queue system to coordinate message processing across multiple channels and teams. This document explains how it works.

## Overview

The queue system acts as a central coordinator between:
- **Channel clients** (Discord, Telegram, WhatsApp) - produce messages
- **Queue processor** - routes and processes messages
- **AI providers** (Claude, Codex) - generate responses
- **Teams** - isolated AI agents with different configs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Message Channels                         â”‚
â”‚         (Discord, Telegram, WhatsApp, Heartbeat)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Write message.json
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ~/.tinyclaw/queue/                         â”‚
â”‚                                                              â”‚
â”‚  incoming/          processing/         outgoing/           â”‚
â”‚  â”œâ”€ msg1.json  â†’   â”œâ”€ msg1.json   â†’   â”œâ”€ msg1.json        â”‚
â”‚  â”œâ”€ msg2.json       â””â”€ msg2.json       â””â”€ msg2.json        â”‚
â”‚  â””â”€ msg3.json                                                â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Queue Processor
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Parallel Processing by Team                     â”‚
â”‚                                                              â”‚
â”‚  Team: coder         Team: writer        Team: assistant    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Message 1â”‚       â”‚ Message 1â”‚        â”‚ Message 1â”‚       â”‚
â”‚  â”‚ Message 2â”‚ ...   â”‚ Message 2â”‚  ...   â”‚ Message 2â”‚ ...   â”‚
â”‚  â”‚ Message 3â”‚       â”‚          â”‚        â”‚          â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚                  â”‚                     â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                  â†“                     â†“
   claude CLI         claude CLI             claude CLI
  (workspace/coder)  (workspace/writer)  (workspace/assistant)
```

## Directory Structure

```
~/.tinyclaw/
â”œâ”€â”€ queue/
â”‚   â”œâ”€â”€ incoming/          # New messages from channels
â”‚   â”‚   â”œâ”€â”€ msg_123456.json
â”‚   â”‚   â””â”€â”€ msg_789012.json
â”‚   â”œâ”€â”€ processing/        # Currently being processed
â”‚   â”‚   â””â”€â”€ msg_123456.json
â”‚   â””â”€â”€ outgoing/          # Responses ready to send
â”‚       â””â”€â”€ msg_123456.json
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ queue.log         # Queue processor logs
â”‚   â”œâ”€â”€ discord.log       # Channel-specific logs
â”‚   â””â”€â”€ telegram.log
â””â”€â”€ files/                # Uploaded files from channels
    â””â”€â”€ image_123.png
```

## Message Flow

### 1. Incoming Message

A channel client receives a message and writes it to `incoming/`:

```json
{
  "channel": "discord",
  "sender": "Alice",
  "senderId": "user_12345",
  "message": "@coder fix the authentication bug",
  "timestamp": 1707739200000,
  "messageId": "discord_msg_123",
  "files": ["/path/to/screenshot.png"]
}
```

**Optional fields:**
- `agent` - Pre-route to specific team (bypasses @team_id parsing)
- `files` - Array of file paths uploaded with message

### 2. Processing

The queue processor (runs every 1 second):

1. **Scans `incoming/`** for new messages
2. **Sorts by timestamp** (oldest first)
3. **Determines target team**:
   - Checks `agent` field (if pre-routed)
   - Parses `@team_id` prefix from message
   - Falls back to `default` team
4. **Moves to `processing/`** (atomic operation)
5. **Routes to team's promise chain** (parallel processing)

### 3. Team Processing

Each team has its own promise chain:

```typescript
// Messages to same team = sequential (preserve conversation order)
teamChain: msg1 â†’ msg2 â†’ msg3

// Different teams = parallel (don't block each other)
@coder:     msg1 â”€â”€â”
@writer:    msg1 â”€â”€â”¼â”€â†’ All run concurrently
@assistant: msg1 â”€â”€â”˜
```

**Per-team isolation:**
- Each team runs in its own `working_directory`
- Separate conversation history (managed by CLI)
- Independent reset flags
- Own configuration files (.claude/, AGENTS.md)

### 4. AI Provider Execution

**Claude (Anthropic):**
```bash
cd ~/workspace/coder/
claude --dangerously-skip-permissions \
  --model claude-sonnet-4-5 \
  -c \  # Continue conversation
  -p "fix the authentication bug"
```

**Codex (OpenAI):**
```bash
cd ~/workspace/coder/
codex exec resume --last \
  --model gpt-5.3-codex \
  --skip-git-repo-check \
  --dangerously-bypass-approvals-and-sandbox \
  --json "fix the authentication bug"
```

### 5. Response

After AI responds, queue processor writes to `outgoing/`:

```json
{
  "channel": "discord",
  "sender": "Alice",
  "message": "I've identified the issue in auth.ts:42...",
  "originalMessage": "@coder fix the authentication bug",
  "timestamp": 1707739205000,
  "messageId": "discord_msg_123",
  "agent": "coder",
  "files": ["/path/to/fix.patch"]
}
```

### 6. Channel Delivery

Channel clients poll `outgoing/` and:
1. Read response for their channel
2. Send message to user
3. Delete the JSON file
4. Handle any file attachments

## Parallel Processing

### How It Works

Each team has its own **promise chain** that processes messages sequentially:

```typescript
const teamProcessingChains = new Map<string, Promise<void>>();

// When message arrives for @coder:
const chain = teamProcessingChains.get('coder') || Promise.resolve();
const newChain = chain.then(() => processMessage(msg));
teamProcessingChains.set('coder', newChain);
```

### Benefits

**Example: 3 messages sent simultaneously**

Sequential (old):
```
@coder fix bug 1     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 30s
@writer docs         [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 20s
@assistant help      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 15s
Total: 65 seconds
```

Parallel (new):
```
@coder fix bug 1     [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 30s
@writer docs         [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 20s â† concurrent!
@assistant help      [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 15s   â† concurrent!
Total: 30 seconds (2.2x faster!)
```

### Conversation Order Preserved

Messages to the **same team** remain sequential:

```
@coder fix bug 1     [â–ˆâ–ˆâ–ˆâ–ˆ] 10s
@coder fix bug 2             [â–ˆâ–ˆâ–ˆâ–ˆ] 10s  â† waits for bug 1
@writer docs         [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 15s        â† parallel with both
```

This ensures:
- âœ… Conversation context is maintained
- âœ… `-c` (continue) flag works correctly
- âœ… No race conditions within a team
- âœ… Teams don't block each other

## Team Routing

### Explicit Routing

Use `@team_id` prefix:

```
User: @coder fix the login bug
â†’ Routes to team "coder"
â†’ Message becomes: "fix the login bug"
```

### Pre-routing

Channel clients can pre-route:

```typescript
const queueData = {
  channel: 'discord',
  message: 'help me',
  agent: 'assistant'  // Pre-routed, no @prefix needed
};
```

### Fallback Logic

```
1. Check message.agent field (if pre-routed)
2. Parse @team_id from message text
3. Look up team in settings.teams
4. Fall back to 'default' team
5. If no default, use first available team
```

### Routing Examples

```
"@coder fix bug"           â†’ team: coder
"help me"                  â†’ team: default
"@unknown test"            â†’ team: default (unknown team)
"@assistant help"          â†’ team: assistant
pre-routed with agent=X    â†’ team: X
```

### Easter Egg: Multiple Teams ğŸ¥š

If you mention multiple teams in one message:

```
User: "@coder @writer fix this bug and document it"

Result:
  â†’ Returns friendly message about upcoming team-to-team collaboration
  â†’ No AI processing (saves tokens!)
  â†’ Suggests sending separate messages to each team
```

**The easter egg message:**
> ğŸš€ **Team-to-Team Collaboration - Coming Soon!**
>
> You mentioned multiple teams: @coder, @writer
>
> Right now, I can only route to one team at a time. But we're working on something cool:
>
> âœ¨ **Multi-Team Coordination** - Teams will be able to collaborate on complex tasks!
> âœ¨ **Smart Routing** - Send instructions to multiple teams at once!
> âœ¨ **Team Handoffs** - One team can delegate to another!
>
> For now, please send separate messages to each team:
> â€¢ `@coder [your message]`
> â€¢ `@writer [your message]`
>
> _Stay tuned for updates! ğŸ‰_

This prevents confusion and teases the upcoming feature!

## Reset System

### Global Reset

Creates `~/.tinyclaw/reset_flag`:

```bash
./tinyclaw.sh reset
```

Next message to **any team** starts fresh (no `-c` flag).

### Per-Team Reset

Creates `~/workspace/{team_id}/reset_flag`:

```bash
./tinyclaw.sh team reset coder
# Or in chat:
@coder /reset
```

Next message to **that team** starts fresh.

### How Resets Work

Queue processor checks before each message:

```typescript
const globalReset = fs.existsSync(RESET_FLAG);
const teamReset = fs.existsSync(`${teamDir}/reset_flag`);

if (globalReset || teamReset) {
  // Don't pass -c flag to CLI
  // Delete flag files
}
```

## File Handling

### Uploading Files

Channels download files to `~/.tinyclaw/files/`:

```
User uploads: image.png
â†’ Saved as: ~/.tinyclaw/files/telegram_123_image.png
â†’ Message includes: [file: /absolute/path/to/image.png]
```

### Sending Files

AI can send files back:

```
AI response: "Here's the diagram [send_file: /path/to/diagram.png]"
â†’ Queue processor extracts file path
â†’ Adds to response.files array
â†’ Channel client sends as attachment
â†’ Tag is stripped from message text
```

## Error Handling

### Missing Teams

If team not found:
```
User: @unknown help
â†’ Routes to: default team
â†’ Logs: WARNING - Team 'unknown' not found, using 'default'
```

### Processing Errors

Errors are caught per-team:

```typescript
newChain.catch(error => {
  log('ERROR', `Error processing message for team ${teamId}: ${error.message}`);
});
```

Failed messages:
- Don't block other teams
- Are logged to `queue.log`
- Response file not created
- Channel client times out gracefully

### Stale Messages

Old messages in `processing/` (crashed mid-process):
- Automatically picked up on restart
- Re-processed from scratch
- Original in `incoming/` is moved again

## Performance

### Throughput

- **Sequential**: 1 message per AI response time (~10-30s)
- **Parallel**: N teams Ã— 1 message per response time
- **3 teams**: ~3x throughput improvement

### Latency

- Queue check: Every 1 second
- Team routing: <1ms (file peek)
- Max latency: 1s + AI response time

### Scaling

**Good for:**
- âœ… Multiple independent teams
- âœ… High message volume
- âœ… Long AI response times

**Limitations:**
- âš ï¸ File-based (not database)
- âš ï¸ Single queue processor instance
- âš ï¸ All teams on same machine

## Debugging

### Check Queue Status

```bash
# See pending messages
ls ~/.tinyclaw/queue/incoming/

# See processing
ls ~/.tinyclaw/queue/processing/

# See responses waiting
ls ~/.tinyclaw/queue/outgoing/

# Watch queue logs
tail -f ~/.tinyclaw/logs/queue.log
```

### Common Issues

**Messages stuck in incoming:**
- Queue processor not running
- Check: `./tinyclaw.sh status`

**Messages stuck in processing:**
- AI CLI crashed or hung
- Manual cleanup: `rm ~/.tinyclaw/queue/processing/*`
- Restart: `./tinyclaw.sh restart`

**No responses generated:**
- Check team routing (wrong @team_id?)
- Check AI CLI is installed (claude/codex)
- Check logs: `tail -f ~/.tinyclaw/logs/queue.log`

**Teams not processing in parallel:**
- Check TypeScript build: `npm run build`
- Check queue processor version in logs

## Advanced Topics

### Custom Queue Implementations

Replace file-based queue with:
- Redis (for multi-instance)
- Database (for persistence)
- Message broker (RabbitMQ, Kafka)

Key interface to maintain:
```typescript
interface QueueMessage {
  channel: string;
  sender: string;
  message: string;
  timestamp: number;
  messageId: string;
  agent?: string;
  files?: string[];
}
```

### Load Balancing

Currently: All teams run on same machine

Future: Route teams to different machines:
```json
{
  "teams": {
    "coder": {
      "host": "worker1.local",
      "working_directory": "/teams/coder"
    },
    "writer": {
      "host": "worker2.local",
      "working_directory": "/teams/writer"
    }
  }
}
```

### Monitoring

Add metrics:
```typescript
- messages_processed_total (by team)
- processing_duration_seconds (by team)
- queue_depth (incoming/processing/outgoing)
- team_active_processing (concurrent count)
```

## See Also

- [TEAM_OF_AGENTS.md](TEAM_OF_AGENTS.md) - Team configuration and management
- [README.md](../README.md) - Main project documentation
- [src/queue-processor.ts](../src/queue-processor.ts) - Implementation
